# AWS Solution Architect Associate Exam -Notes

Revised On: 05.12.2020

## Architecture Evolution

### Drawbags of Monolithic Applications

* All things/eggs in one basket.
* You can only scale vertically.
* After you scale vertically, downtime is required to scale down
* So, you keep paying cost for vertical scaling till you scale down.
* Maintenance can be really complicated.

### Drawbags of Tiered Applications

* You build each component on their respective instance. This way, one can scale horizontally or vertically individual instance. With this approach, we have overcome the drawbags of monolithic architecture
* But then, each layer needs to wait or run. if any of the layer is paused, then entire process is likely to fail. This means, if there is process which is not doing things, there is high chance compute, storage and networking is wasted.

### Decoupling using Queue

* Here you can use queue based Architecture.
* So here is no dependency between the tiers. I meant, if you upload a video, the upload process is completed irrespective if the processing window is there or no. All the information about Upload tier is queued. Then, processing queue take the information from the queue and process it. If there are multiple items in the queue, then you can employ Auto scale group and based on the queue length, you can trigger the no of instances. Once the queue is empty, you can design ASG in such way that instance will auto delete.
* This is at high level **asynchronous** communication between various tiers

### Event Driven Architecture

* Event Producers: Mouse movement is a event.
* Event Consumer: What to do when mouse is moved, is called event consumer. Consumer consumes this event and decide next course of actions.

Be it Event Producers or Consumer, in both case resources are consumed. But they are not sitting idle/waiting to event occurs/Producer.

There is another key component between event producers and event consumer and it is called **Event Router**. Event Router is kind of Bus, it looks for event and then knows which consumer to send this event.

## Lambda

* It is Function as Service. You may call it serverless
* You develop the code in your favorite language, paste the code and execute.
* * For every language, there is runtime available. If you have developed a code in java, then there is java runtime for it.
* Lamda is more valuable when you combine it with event driven architecture.
* Your billed only for the time, the code executes
* You need execution role from IAM perspective.
* Lamda is public services, this means it can invoke publicly available API But it cannot access any AWS resources. For this, Lamda must be deployed in VPC and the configure VPC/Lambda to have internet access.
* Here, input can be taken from the AWS resource like DynamoDB or S3 (assuming you have IAM roles defined to access the resources) and output can be send to S3 (when objects is the output) and DynamoDB (when the output is data)
* 15 Minutes execution time limit.
* There is no persistence storage. So you should load from and to - to the persistence storage.

## CloudWatch Events and EventBridge

* CloudWatch Events are stream of events which are generated when e.g. the EC2 is shutdown, rebooted or terminated.
* Event bridge is replacing CloudWatch Events.
* Event bridge brings in events from 3rd party and as well as custom applications.
* CloudWatch events has only one bus. It is not visible but it exists
* But eventbridge can have multiple Buses
* You monitor this Bus for specific events or specific schedules. When this is found/noticed, we can invoke Lamda function. You achieve this using Rules
  * Pattern matching rules
  * Schedule Rule
* EC2 generate a event and sent it to the Bus. We check for stop event and then can invoke a Lamda function to start EC2 instance.
* You can invoke more than one Lamda function. It is parallel, so there is no order.
